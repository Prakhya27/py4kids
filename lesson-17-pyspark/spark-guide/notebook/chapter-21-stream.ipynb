{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"chapter-21-stream\")\\\n",
    "    .getOrCreate()\n",
    "\n",
    "import os\n",
    "SPARK_BOOK_DATA_PATH = os.environ['SPARK_BOOK_DATA_PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "static = spark.read.json(SPARK_BOOK_DATA_PATH + \"/data/activity-data/\")\n",
    "dataSchema = static.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "streaming = spark.readStream.schema(dataSchema).option(\"maxFilesPerTrigger\", 1)\\\n",
    "  .json(SPARK_BOOK_DATA_PATH + \"/data/activity-data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "activityCounts = streaming.groupBy(\"gt\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "activityQuery = activityCounts.writeStream.queryName(\"activity_counts\")\\\n",
    "  .format(\"memory\").outputMode(\"complete\")\\\n",
    "  .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|        gt|count|\n",
      "+----------+-----+\n",
      "|  stairsup|10452|\n",
      "|       sit|12309|\n",
      "|     stand|11385|\n",
      "|      walk|13256|\n",
      "|      bike|10797|\n",
      "|stairsdown| 9365|\n",
      "|      null|10448|\n",
      "+----------+-----+\n",
      "\n",
      "+----------+-----+\n",
      "|        gt|count|\n",
      "+----------+-----+\n",
      "|  stairsup|20905|\n",
      "|       sit|24619|\n",
      "|     stand|22770|\n",
      "|      walk|26512|\n",
      "|      bike|21594|\n",
      "|stairsdown|18729|\n",
      "|      null|20895|\n",
      "+----------+-----+\n",
      "\n",
      "+----------+-----+\n",
      "|        gt|count|\n",
      "+----------+-----+\n",
      "|  stairsup|31357|\n",
      "|       sit|36929|\n",
      "|     stand|34155|\n",
      "|      walk|39768|\n",
      "|      bike|32391|\n",
      "|stairsdown|28094|\n",
      "|      null|31342|\n",
      "+----------+-----+\n",
      "\n",
      "+----------+-----+\n",
      "|        gt|count|\n",
      "+----------+-----+\n",
      "|  stairsup|41809|\n",
      "|       sit|49238|\n",
      "|     stand|45539|\n",
      "|      walk|53024|\n",
      "|      bike|43187|\n",
      "|stairsdown|37459|\n",
      "|      null|41791|\n",
      "+----------+-----+\n",
      "\n",
      "+----------+-----+\n",
      "|        gt|count|\n",
      "+----------+-----+\n",
      "|  stairsup|52262|\n",
      "|       sit|61545|\n",
      "|     stand|56924|\n",
      "|      walk|66280|\n",
      "|      bike|53985|\n",
      "|stairsdown|46823|\n",
      "|      null|52240|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "from time import sleep\n",
    "for x in range(5):\n",
    "    spark.sql(\"SELECT * FROM activity_counts\").show()\n",
    "    sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|        gt| count|\n",
      "+----------+------+\n",
      "|  stairsup|177717|\n",
      "|       sit|209235|\n",
      "|     stand|193549|\n",
      "|      walk|225352|\n",
      "|      bike|183560|\n",
      "|stairsdown|159179|\n",
      "|      null|177612|\n",
      "+----------+------+\n",
      "\n",
      "+----------+------+\n",
      "|        gt| count|\n",
      "+----------+------+\n",
      "|  stairsup|188178|\n",
      "|       sit|221543|\n",
      "|     stand|204933|\n",
      "|      walk|238608|\n",
      "|      bike|194357|\n",
      "|stairsdown|168539|\n",
      "|      null|188057|\n",
      "+----------+------+\n",
      "\n",
      "+----------+------+\n",
      "|        gt| count|\n",
      "+----------+------+\n",
      "|  stairsup|198636|\n",
      "|       sit|233851|\n",
      "|     stand|216319|\n",
      "|      walk|251864|\n",
      "|      bike|205154|\n",
      "|stairsdown|177899|\n",
      "|      null|198503|\n",
      "+----------+------+\n",
      "\n",
      "+----------+------+\n",
      "|        gt| count|\n",
      "+----------+------+\n",
      "|  stairsup|209097|\n",
      "|       sit|246159|\n",
      "|     stand|227703|\n",
      "|      walk|265120|\n",
      "|      bike|215951|\n",
      "|stairsdown|187259|\n",
      "|      null|208949|\n",
      "+----------+------+\n",
      "\n",
      "+----------+------+\n",
      "|        gt| count|\n",
      "+----------+------+\n",
      "|  stairsup|219558|\n",
      "|       sit|258467|\n",
      "|     stand|239087|\n",
      "|      walk|278376|\n",
      "|      bike|226748|\n",
      "|stairsdown|196618|\n",
      "|      null|219395|\n",
      "+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "from time import sleep\n",
    "for x in range(5):\n",
    "    spark.sql(\"SELECT * FROM activity_counts\").show()\n",
    "    sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<pyspark.sql.streaming.StreamingQuery at 0x7f25f3acdc88>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.streams.active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.sql.functions import expr\n",
    "simpleTransform = streaming.withColumn(\"stairs\", expr(\"gt like '%stairs%'\"))\\\n",
    "  .where(\"stairs\")\\\n",
    "  .where(\"gt is not null\")\\\n",
    "  .select(\"gt\", \"model\", \"arrival_time\", \"creation_time\")\\\n",
    "  .writeStream\\\n",
    "  .queryName(\"simple_transform\")\\\n",
    "  .format(\"memory\")\\\n",
    "  .outputMode(\"append\")\\\n",
    "  .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "deviceModelStats = streaming.cube(\"gt\", \"model\").avg()\\\n",
    "  .drop(\"avg(Arrival_time)\")\\\n",
    "  .drop(\"avg(Creation_Time)\")\\\n",
    "  .drop(\"avg(Index)\")\\\n",
    "  .writeStream.queryName(\"device_counts\")\\\n",
    "  .format(\"memory\")\\\n",
    "  .outputMode(\"complete\")\\\n",
    "  .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "historicalAgg = static.groupBy(\"gt\", \"model\").avg()\n",
    "deviceModelStats = streaming.drop(\"Arrival_Time\", \"Creation_Time\", \"Index\")\\\n",
    "  .cube(\"gt\", \"model\").avg()\\\n",
    "  .join(historicalAgg, [\"gt\", \"model\"])\\\n",
    "  .writeStream.queryName(\"device_counts\")\\\n",
    "  .format(\"memory\")\\\n",
    "  .outputMode(\"complete\")\\\n",
    "  .start()\n",
    "\n",
    "\n",
    "# COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subscribe to 1 topic\n",
    "df1 = spark.readStream.format(\"kafka\")\\\n",
    "  .option(\"kafka.bootstrap.servers\", \"host1:port1,host2:port2\")\\\n",
    "  .option(\"subscribe\", \"topic1\")\\\n",
    "  .load()\n",
    "# Subscribe to multiple topics\n",
    "df2 = spark.readStream.format(\"kafka\")\\\n",
    "  .option(\"kafka.bootstrap.servers\", \"host1:port1,host2:port2\")\\\n",
    "  .option(\"subscribe\", \"topic1,topic2\")\\\n",
    "  .load()\n",
    "# Subscribe to a pattern\n",
    "df3 = spark.readStream.format(\"kafka\")\\\n",
    "  .option(\"kafka.bootstrap.servers\", \"host1:port1,host2:port2\")\\\n",
    "  .option(\"subscribePattern\", \"topic.*\")\\\n",
    "  .load()\n",
    "\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "df1.selectExpr(\"topic\", \"CAST(key AS STRING)\", \"CAST(value AS STRING)\")\\\n",
    "  .writeStream\\\n",
    "  .format(\"kafka\")\\\n",
    "  .option(\"kafka.bootstrap.servers\", \"host1:port1,host2:port2\")\\\n",
    "  .option(\"checkpointLocation\", \"/to/HDFS-compatible/dir\")\\\n",
    "  .start()\n",
    "df1.selectExpr(\"CAST(key AS STRING)\", \"CAST(value AS STRING)\")\\\n",
    "  .writeStream\\\n",
    "  .format(\"kafka\")\\\n",
    "  .option(\"kafka.bootstrap.servers\", \"host1:port1,host2:port2\")\\\n",
    "  .option(\"checkpointLocation\", \"/to/HDFS-compatible/dir\")\\\n",
    "  .option(\"topic\", \"topic1\")\\\n",
    "  .start()\n",
    "\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "socketDF = spark.readStream.format(\"socket\")\\\n",
    "  .option(\"host\", \"localhost\").option(\"port\", 9999).load()\n",
    "\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "activityCounts.writeStream.trigger(processingTime='5 seconds')\\\n",
    "  .format(\"console\").outputMode(\"complete\").start()\n",
    "\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "activityCounts.writeStream.trigger(once=True)\\\n",
    "  .format(\"console\").outputMode(\"complete\").start()\n",
    "\n",
    "\n",
    "# COMMAND ----------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
