{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "va = VectorAssembler()\\\n",
    "  .setInputCols([\"Quantity\", \"UnitPrice\"])\\\n",
    "  .setOutputCol(\"features\")\n",
    "\n",
    "sales = va.transform(spark.read.format(\"csv\")\n",
    "  .option(\"header\", \"true\")\n",
    "  .option(\"inferSchema\", \"true\")\n",
    "  .load(\"/data/retail-data/by-day/*.csv\")\n",
    "  .limit(50)\n",
    "  .coalesce(1)\n",
    "  .where(\"Description IS NOT NULL\"))\n",
    "\n",
    "sales.cache()\n",
    "\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.ml.clustering import KMeans\n",
    "km = KMeans().setK(5)\n",
    "print km.explainParams()\n",
    "kmModel = km.fit(sales)\n",
    "\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "summary = kmModel.summary\n",
    "print summary.clusterSizes # number of points\n",
    "kmModel.computeCost(sales)\n",
    "centers = kmModel.clusterCenters()\n",
    "print(\"Cluster Centers: \")\n",
    "for center in centers:\n",
    "    print(center)\n",
    "\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.ml.clustering import BisectingKMeans\n",
    "bkm = BisectingKMeans().setK(5).setMaxIter(5)\n",
    "bkmModel = bkm.fit(sales)\n",
    "\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "summary = bkmModel.summary\n",
    "print summary.clusterSizes # number of points\n",
    "kmModel.computeCost(sales)\n",
    "centers = kmModel.clusterCenters()\n",
    "print(\"Cluster Centers: \")\n",
    "for center in centers:\n",
    "    print(center)\n",
    "\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.ml.clustering import GaussianMixture\n",
    "gmm = GaussianMixture().setK(5)\n",
    "print gmm.explainParams()\n",
    "model = gmm.fit(sales)\n",
    "\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "summary = model.summary\n",
    "print model.weights\n",
    "model.gaussiansDF.show()\n",
    "summary.cluster.show()\n",
    "summary.clusterSizes\n",
    "summary.probability.show()\n",
    "\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.ml.feature import Tokenizer, CountVectorizer\n",
    "tkn = Tokenizer().setInputCol(\"Description\").setOutputCol(\"DescOut\")\n",
    "tokenized = tkn.transform(sales.drop(\"features\"))\n",
    "cv = CountVectorizer()\\\n",
    "  .setInputCol(\"DescOut\")\\\n",
    "  .setOutputCol(\"features\")\\\n",
    "  .setVocabSize(500)\\\n",
    "  .setMinTF(0)\\\n",
    "  .setMinDF(0)\\\n",
    "  .setBinary(True)\n",
    "cvFitted = cv.fit(tokenized)\n",
    "prepped = cvFitted.transform(tokenized)\n",
    "\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.ml.clustering import LDA\n",
    "lda = LDA().setK(10).setMaxIter(5)\n",
    "print lda.explainParams()\n",
    "model = lda.fit(prepped)\n",
    "\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "model.describeTopics(3).show()\n",
    "cvFitted.vocabulary\n",
    "\n",
    "\n",
    "# COMMAND ----------\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
